{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_dataset = pickle.load(open(\"save/T007_Transformer/train_dataset.p\", \"rb\"))\n",
    "test_dataset = pickle.load(open(\"save/T007_Transformer/test_dataset.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "#from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from https://stackoverflow.com/questions/61616810/how-to-do-cubic-spline-interpolation-and-integration-in-pytorch\n",
    "\n",
    "#import torch\n",
    "\n",
    "def h_poly(t):\n",
    "    tt = t[None, :]**torch.arange(4, device=t.device)[:, None]\n",
    "    A = torch.tensor([\n",
    "        [1, 0, -3, 2],\n",
    "        [0, 1, -2, 1],\n",
    "        [0, 0, 3, -2],\n",
    "        [0, 0, -1, 1]\n",
    "    ], dtype=t.dtype, device=t.device)\n",
    "    return A @ tt\n",
    "\n",
    "\n",
    "def interp(x, y, xs):\n",
    "    m = (y[1:] - y[:-1]) / (x[1:] - x[:-1])\n",
    "    m = torch.cat([m[[0]], (m[1:] + m[:-1]) / 2, m[[-1]]])\n",
    "    idxs = torch.searchsorted(x[1:], xs)\n",
    "    dx = (x[idxs + 1] - x[idxs])\n",
    "    hh = h_poly((xs - x[idxs]) / dx)\n",
    "    return hh[0] * y[idxs] + hh[1] * m[idxs] * dx + hh[2] * y[idxs + 1] + hh[3] * m[idxs + 1] * dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirfoilModel(LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = 128\n",
    "        #self.hparams.batch_size = 64\n",
    "        self.lr=1e-3\n",
    "        \n",
    "        self.train_variance = 1.0\n",
    "        \n",
    "        c1 = 16\n",
    "        c2 = 8\n",
    "        k2 = 8\n",
    "        c3 = 32\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.layer_0 = nn.Conv1d(in_channels=6,out_channels=c1,kernel_size=5,stride=1, padding=2)\n",
    "\n",
    "        self.layer_11 = nn.Conv1d(in_channels=c1,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_12 = nn.Conv1d(in_channels=c2,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_13 = nn.Conv1d(in_channels=c2,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_14 = nn.Conv1d(in_channels=c2,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.relu_11 = nn.ReLU()\n",
    "        self.relu_12 = nn.ReLU()\n",
    "        self.relu_13 = nn.ReLU()\n",
    "        self.relu_14 = nn.ReLU()\n",
    "\n",
    "        self.layer_2 = nn.Conv1d(in_channels=8*4,out_channels=c3,kernel_size=5,stride=1, padding=2)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=32, nhead=8, dim_feedforward=64, dropout=0.001)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=3)\n",
    "        \n",
    "        self.output = nn.Conv1d(in_channels=c3,out_channels=11,kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.beta_dist = torch.distributions.beta.Beta(2,2)\n",
    "        \n",
    "        self.ma_aoa_lin1 = nn.Linear(2,16)\n",
    "        self.ma_aoa_relu1 = nn.ReLU()\n",
    "        self.ma_aoa_lin2 = nn.Linear(16,32)\n",
    "        self.ma_aoa_relu2 = nn.ReLU()\n",
    "        \n",
    "        latenc_layers = nn.TransformerDecoderLayer(d_model=32, nhead=8, dim_feedforward=64, dropout=0.001)\n",
    "        self.latenc_transformer = nn.TransformerDecoder(latenc_layers, num_layers=2)        \n",
    "        \n",
    "        decoder_layers = nn.TransformerDecoderLayer(d_model=32, nhead=8, dim_feedforward=64, dropout=0.001)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers=3)\n",
    "        \n",
    "    def data_augmentation(self, x):\n",
    "        \n",
    "        s = x[:,1]\n",
    "        ds = s[:,1:] - s[:,:-1]\n",
    "        \n",
    "        rv = self.beta_dist.rsample([s.shape[0], s.shape[1]-2]).to(self.device)\n",
    "        snew = s.clone()\n",
    "        #print(snew.device, rv.device, ds.device)\n",
    "        snew[:,1:-1] += 0.5 * ( (rv > 0)*ds[:,1:] - (rv < 0)* ds[:,:-1] )\n",
    "\n",
    "        #xnew = interp(s, x, snew)\n",
    "        \n",
    "        xnew = torch.zeros_like(x, device=self.device)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                xnew[i,j] = interp(s[i], x[i,j], snew[i])\n",
    "        \n",
    "        indices = torch.rand(xnew.shape[1]) >= 0.25\n",
    "        xnew = xnew[:,indices]\n",
    "        \n",
    "        return xnew\n",
    "    \n",
    "    def augment_output(self, x, y):\n",
    "        \n",
    "        s = x[:,1]\n",
    "        ds = s[:,1:] - s[:,:-1]\n",
    "        \n",
    "        rv = self.beta_dist.rsample([s.shape[0], s.shape[1]-2]).to(self.device)\n",
    "        snew = s.clone()\n",
    "        #print(snew.device, rv.device, ds.device)\n",
    "        snew[:,1:-1] += 0.5 * ( (rv > 0)*ds[:,1:] - (rv < 0)* ds[:,:-1] )\n",
    "\n",
    "        #xnew = interp(s, x, snew)\n",
    "        \n",
    "        xnew = torch.zeros_like(x, device=self.device)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                xnew[i,j] = interp(s[i], x[i,j], snew[i])\n",
    "                \n",
    "        ynew = torch.zeros_like(y, device=self.device)\n",
    "        for i in range(y.shape[0]):\n",
    "            for j in range(y.shape[1]):\n",
    "                ynew[i,j] = interp(s[i], y[i,j], snew[i])\n",
    "        \n",
    "        indices = torch.rand(xnew.shape[1]) >= 0.25\n",
    "        xnew = xnew[:,indices]\n",
    "        ynew = ynew[:,indices]\n",
    "        \n",
    "        return xnew, ynew\n",
    "        \n",
    "    def airfoil_encoder(self, x):\n",
    "        \n",
    "        #xxx = torch.cat((x, x, x), dim=2)\n",
    "        #x_0 = self.layer_0(xxx)\n",
    "        x_0 = self.layer_0(x)\n",
    "\n",
    "        x_11 = self.relu_11(self.layer_11(x_0))\n",
    "        x_12 = self.relu_12(self.layer_12(x_11))\n",
    "        x_13 = self.relu_13(self.layer_13(x_12))\n",
    "        x_14 = self.relu_14(self.layer_14(x_13))\n",
    "\n",
    "        x_1 = torch.cat((x_11, x_12, x_13, x_14), dim=1)\n",
    "        \n",
    "        x_2 = self.relu_2(self.layer_2(x_1))\n",
    "        \n",
    "        ### Insert Transformer!\n",
    "        \n",
    "        x_3 = x_2\n",
    "        \n",
    "        return x_3\n",
    "        \n",
    "    def latent_encoder(self, x_3, ma, aoa):\n",
    "        \n",
    "        #ma = torch.ones(x_3.shape[0], 1,193).to(self.device)*ma.view(-1, 1, 1)\n",
    "        #aoa = torch.ones(x_3.shape[0], 1, 193).to(self.device)*aoa.view(-1, 1, 1)\n",
    "        \n",
    "        #print(\"lat\", x_3.device, ma.device, aoa.device)\n",
    "        \n",
    "        ma_aoa = torch.stack((ma,aoa)).to(self.device)\n",
    "        ma_aoa1 = self.ma_aoa_relu1(self.ma_aoa_lin1(ma_aoa.T))\n",
    "        ma_aoa2 = self.ma_aoa_relu2(self.ma_aoa_lin2(ma_aoa1)).view(-1,1,32)\n",
    "        \n",
    "        #relu(lin(cat((ma,aoa))))\n",
    "        #x_4 = torch.cat((x_3, aoa, ma), dim=1)        \n",
    "        \n",
    "        ### Insert Transformer!\n",
    "        \n",
    "        #z = self.transformer_encoder(x_4.transpose(1,2))\n",
    "        \n",
    "        #print(ma_aoa2.shape, x_3.shape)\n",
    "        #print(ma_aoa2.device, x_3.device)\n",
    "        \n",
    "        z = self.latenc_transformer(ma_aoa2, x_3.transpose(1,2))\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    \n",
    "    def airfoil_predictor(self, z, x_output):\n",
    "        \n",
    "        ### Insert Transformer!\n",
    "        \n",
    "        #y = self.output(z.transpose(1,2))      \n",
    "        \n",
    "        \n",
    "        #x3_output = self.airfoil_encoder(x_output)\n",
    "        \n",
    "        #print(z.shape, x_output.shape, x3_output.shape)\n",
    "        \n",
    "        #y = self.transformer_decoder(x3_output, z.transpose(1,2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        x3_output = self.airfoil_encoder(x_output).transpose(1,2).transpose(0,1)\n",
    "        z = z.transpose(0,1)\n",
    "        \n",
    "        #print(z.shape, x_output.shape, x3_output.shape)\n",
    "\n",
    "        y = self.transformer_decoder(x3_output, z).transpose(0,1).transpose(1,2)\n",
    "        \n",
    "        out = self.output(y)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(self, x, ma, aoa):\n",
    "        \n",
    "        xnew = self.data_augmentation(x)\n",
    "        x3 = self.airfoil_encoder(xnew)\n",
    "        z = self.latent_encoder(x3, ma, aoa)\n",
    "        y = self.airfoil_predictor(z)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        qoip, ma, _, aoa = batch\n",
    "        \n",
    "        #print(qoip.device, ma.device, aoa.device)\n",
    "        \n",
    "        x = qoip[:,:6,:]\n",
    "        y_target = qoip\n",
    "        \n",
    "        xout, y_target = self.augment_output(x.clone(), y_target.clone())\n",
    "        \n",
    "        xnew = self.data_augmentation(x.clone())\n",
    "        x3 = self.airfoil_encoder(xnew)\n",
    "        z = self.latent_encoder(x3, ma, aoa)\n",
    "        #y = self.airfoil_predictor(z, self.data_augmentation(x))\n",
    "        y = self.airfoil_predictor(z, xout)\n",
    "        \n",
    "        #y[:,5,:] = 10. * y[:,5,:]\n",
    "        #y_target[:,5,:] = 10. * y_target[:,5,:]\n",
    "        \n",
    "        \n",
    "        loss1 = F.mse_loss(y, y_target) * 1e6\n",
    "        \n",
    "        loss = loss1\n",
    "        \n",
    "        self.log('train_loss', loss1)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        qoip, ma, _, aoa = batch\n",
    "        x = qoip[:,:6,:]\n",
    "        y_target = qoip\n",
    "        \n",
    "        #print(qoip.device, ma.device, aoa.device)\n",
    "        \n",
    "        #xnew = self.data_augmentation(x)\n",
    "        x3 = self.airfoil_encoder(x)\n",
    "        z = self.latent_encoder(x3, ma, aoa)\n",
    "        y = self.airfoil_predictor(z, x)\n",
    "        \n",
    "        #y[:,5,:] *= 10.\n",
    "        #y_target[:,5,:] *= 10.\n",
    "        \n",
    "        loss1 = F.mse_loss(y, y_target) * 1e6\n",
    "        \n",
    "        loss = loss1\n",
    "        \n",
    "        self.log('val_loss', loss1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2000, eta_min=0.0001)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        #print(\"get dataloader \", self.batch_size)\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, num_workers=0, shuffle=True, pin_memory=True)    \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=len(test_dataset), num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AirfoilModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "trainer = Trainer(gpus=1, weights_summary='full', precision=16, check_val_every_n_epoch=2, max_epochs=10_000,\n",
    "                 limit_train_batches=0.5, auto_lr_find=False, callbacks=[lr_monitor]) #, auto_scale_batch_size=None\n",
    "#train_loader = DataLoader(train_dataset, batch_size=1468, shuffle=True, pin_memory=True)\n",
    "#val_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "#trainer.fit(model, train_loader)\n",
    "#trainer.tune(model)\n",
    "model.batch_size = 8\n",
    "model.train_variance = 0.01 #1.0\n",
    "model.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ]
}