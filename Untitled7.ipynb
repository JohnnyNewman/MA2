{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn = os.path.join(\"F:\\\\Uni\\\\Masterarbeit\\\\Daten\", 'T007.h5')\n",
    "#db = h5py.File(fn, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"F:\\\\Uni\\\\Masterarbeit\\\\Daten\\\\CollectedData\\\\T007\"\n",
    "\n",
    "AOA = pickle.load(open(os.path.join(path, \"AOA_mat.p\"), \"rb\"))\n",
    "DVS = pickle.load(open(os.path.join(path, \"dv_list.p\"), \"rb\"))\n",
    "MA = pickle.load(open(os.path.join(path, \"Ma_mat.p\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qois(surface_flow, Ma=.729, AOA=2.31, Re=6.5e6, T=288.15):\n",
    "    x = surface_flow[\"x\"][:]\n",
    "    y = surface_flow[\"y\"][:]\n",
    "    xp = np.hstack((x[-1:], x))\n",
    "    yp = np.hstack((y[-1:], y))\n",
    "    dx = xp[1:] - xp[:-1]\n",
    "    dy = yp[1:] - yp[:-1]\n",
    "    ds = np.sqrt(np.power(dx, 2.) + np.power(dy, 2.))\n",
    "    dxy = np.vstack((dx,dy))\n",
    "    rot = np.array([[0, 1], [-1, 0]])\n",
    "    nxy = rot @ dxy\n",
    "    nxy[0,:] = nxy[0,:] / ds\n",
    "    nxy[1,:] = nxy[1,:] / ds\n",
    "    s = ds.cumsum()\n",
    "    #sp = np.hstack((np.array([0.]), s))\n",
    "    #spn = sp / sp[-1]\n",
    "    sn = s / s[-1]\n",
    "    \n",
    "    Rs = 287.1\n",
    "    l_ref = 1\n",
    "    mu_ref = 1.716e-5\n",
    "    T_ref = 273.15\n",
    "    S = 110.4\n",
    "    gamma = 1.4\n",
    "    \n",
    "    V = Ma*np.sqrt(gamma*Rs*T)\n",
    "    mu = mu_ref*np.power(T/T_ref, 1.5)*(T_ref+S)/(T+S)\n",
    "    rho = Re*mu/(V*l_ref)\n",
    "    q = 0.5*rho*V*V\n",
    "    p = rho*Rs*T\n",
    "    \n",
    "    #print(sp.shape)\n",
    "    \n",
    "    qoi = np.vstack((np.zeros(192), np.zeros(192), np.zeros(192), np.zeros(192), surface_flow[\"x\"], surface_flow[\"y\"], surface_flow[\"Density\"]/rho, surface_flow[\"Energy\"]/(q+p), surface_flow[\"Pressure_Coefficient\"], surface_flow[\"Skin_Friction_Coefficient_x\"], surface_flow[\"Skin_Friction_Coefficient_y\"]))\n",
    "    qoip = np.hstack((qoi[:, -1:], qoi))\n",
    "    qoip[0,1:] = s\n",
    "    qoip[1,1:] = sn\n",
    "    #qoip[0,0] = 0.\n",
    "    #qoip[1,0] = 0.\n",
    "    qoip[2,1:] = nxy[0,:]\n",
    "    qoip[2,:-1] += nxy[0,:]\n",
    "    qoip[2,1:-1] *= 0.5\n",
    "    qoip[3,1:] = nxy[1,:]\n",
    "    qoip[3,:-1] += nxy[1,:]\n",
    "    qoip[3,1:-1] *= 0.5\n",
    "    qoip[5] *= 10.\n",
    "    \n",
    "    \n",
    "    return qoip\n",
    "\n",
    "\n",
    "data = []\n",
    "fn = \"T007.h5\"\n",
    "with h5py.File(fn, \"r\") as db:\n",
    "    #print(db['DESIGNS'].keys())\n",
    "    i = 0\n",
    "    for dsn_name, dsn in db['DESIGNS'].items():\n",
    "        print (dsn_name, dsn)\n",
    "        #print(dsn.keys(), dsn[\"ADJOINT_DRAG/surface_adjoint.csv\"].keys())\n",
    "        print(\"DIRECT/surface_flow.csv\" in dsn, \"ADJOINT_DRAG/surface_adjoint.csv\" in dsn)\n",
    "        if \"DIRECT/surface_flow.csv\" in dsn and \"ADJOINT_DRAG/surface_adjoint.csv\" in dsn:\n",
    "            surface_flow = dsn[\"DIRECT/surface_flow.csv\"]        \n",
    "            qoip = get_qois(surface_flow)\n",
    "\n",
    "            #print(dsn.keys())\n",
    "            adj_surface_flow = dsn[\"ADJOINT_DRAG/surface_adjoint.csv\"]\n",
    "            print(adj_surface_flow.keys())\n",
    "            ### muss noch zu qoip hinzugefÃ¼gt werden\n",
    "\n",
    "            if qoip.shape == (11,193):\n",
    "                data.append(qoip)\n",
    "                if not int(dsn_name[-4:]) == i:\n",
    "                    print(\"Mismtch\", i, dsn_name)\n",
    "                \n",
    "                print(True)\n",
    "                i += 1\n",
    "        \n",
    "\n",
    "\n",
    "#dataset = torch.utils.data.TensorDataset(torch.from_numpy(np.stack(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "\n",
    "aoa = torch.from_numpy(AOA[:N])\n",
    "dvs = torch.from_numpy(np.stack(DVS[:N]))\n",
    "ma = torch.from_numpy(MA[:N])\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(np.stack(data)).float(), ma.float(), dvs.float(), aoa.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"12.011614\".split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fn, \"r\") as db:\n",
    "    dsn = db[\"DESIGNS/DSN_0023\"]\n",
    "    surface_flow = dsn[\"DIRECT/surface_flow.csv\"]\n",
    "    adj_surface_flow = dsn[\"ADJOINT_DRAG/surface_adjoint.csv\"]\n",
    "    for k in adj_surface_flow.keys():\n",
    "        print(k, adj_surface_flow[k][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "#from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from https://stackoverflow.com/questions/61616810/how-to-do-cubic-spline-interpolation-and-integration-in-pytorch\n",
    "\n",
    "#import torch\n",
    "\n",
    "def h_poly(t):\n",
    "    tt = t[None, :]**torch.arange(4, device=t.device)[:, None]\n",
    "    A = torch.tensor([\n",
    "        [1, 0, -3, 2],\n",
    "        [0, 1, -2, 1],\n",
    "        [0, 0, 3, -2],\n",
    "        [0, 0, -1, 1]\n",
    "    ], dtype=t.dtype, device=t.device)\n",
    "    return A @ tt\n",
    "\n",
    "\n",
    "def interp(x, y, xs):\n",
    "    m = (y[1:] - y[:-1]) / (x[1:] - x[:-1])\n",
    "    m = torch.cat([m[[0]], (m[1:] + m[:-1]) / 2, m[[-1]]])\n",
    "    idxs = torch.searchsorted(x[1:], xs)\n",
    "    dx = (x[idxs + 1] - x[idxs])\n",
    "    hh = h_poly((xs - x[idxs]) / dx)\n",
    "    return hh[0] * y[idxs] + hh[1] * m[idxs] * dx + hh[2] * y[idxs + 1] + hh[3] * m[idxs + 1] * dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset[:3]\n",
    "\n",
    "qoip = batch[0]\n",
    "\n",
    "x = qoip[:,:6]\n",
    "\n",
    "s = x[:,1]\n",
    "s.shape, qoip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = s\n",
    "y = qoip[:,6:]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (y[:,:,1:] - y[:,:,:-1]) / (x[:,1:] - x[:,:-1])\n",
    "m\n",
    "#m = torch.cat([m[[0]], (m[1:] + m[:-1]) / 2, m[[-1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 6, 7)\n",
    "y = x.sin()\n",
    "xs = torch.linspace(0, 6, 101)\n",
    "\n",
    "m = (y[1:] - y[:-1]) / (x[1:] - x[:-1])\n",
    "m = torch.cat([m[[0]], (m[1:] + m[:-1]) / 2, m[[-1]]])\n",
    "idxs = torch.searchsorted(x[1:], xs)\n",
    "dx = (x[idxs + 1] - x[idxs])\n",
    "hh = h_poly((xs - x[idxs]) / dx)\n",
    "\n",
    "m, idxs, dx, hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 6, 7)\n",
    "y = x.sin()\n",
    "xs = torch.linspace(0, 6, 101)\n",
    "ys = interp(x, y, xs)\n",
    "#Ys = integ(x, y, xs)\n",
    "plt.scatter(x, y, label='Samples', color='purple')\n",
    "plt.plot(xs, ys, label='Interpolated curve')\n",
    "plt.plot(xs, xs.sin(), '--', label='True Curve')\n",
    "#plt.plot(xs, Ys, label='Spline Integral')\n",
    "#plt.plot(xs, 1-xs.cos(), '--', label='True Integral')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qoip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(qoip[1])\n",
    "y = torch.from_numpy(qoip[5])\n",
    "xs = torch.linspace(0, 1, 10001)\n",
    "ys = interp(x, y, xs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.scatter(x, y, label='Samples', color='purple')\n",
    "plt.plot(xs, ys, label='Interpolated curve')\n",
    "#plt.plot(xs, xs.sin(), '--', label='True Curve')\n",
    "#plt.plot(xs, Ys, label='Spline Integral')\n",
    "#plt.plot(xs, 1-xs.cos(), '--', label='True Integral')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 1, 101)\n",
    "x\n",
    "\n",
    "y = torch.exp(-2*(x-0.5)**2)\n",
    "y = torch.sin(30*x/np.pi)\n",
    "\n",
    "x2 = torch.rand(10)\n",
    "y2 = torch.sin(30*x2/np.pi)\n",
    "#ys2 = interp(x2,y2,x)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.plot(x2,y2, 'o')\n",
    "#plt.plot(x, ys2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.85 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirfoilModel(LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = 128\n",
    "        #self.hparams.batch_size = 64\n",
    "        self.lr=1e-3\n",
    "        \n",
    "        self.train_variance = 1.0\n",
    "        \n",
    "        c1 = 16\n",
    "        c2 = 8\n",
    "        k2 = 8\n",
    "        c3 = 32\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.layer_0 = nn.Conv1d(in_channels=6,out_channels=c1,kernel_size=5,stride=1, padding=2)\n",
    "\n",
    "        self.layer_11 = nn.Conv1d(in_channels=c1,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_12 = nn.Conv1d(in_channels=c2,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_13 = nn.Conv1d(in_channels=c2,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_14 = nn.Conv1d(in_channels=c2,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.relu_11 = nn.ReLU()\n",
    "        self.relu_12 = nn.ReLU()\n",
    "        self.relu_13 = nn.ReLU()\n",
    "        self.relu_14 = nn.ReLU()\n",
    "\n",
    "        self.layer_2 = nn.Conv1d(in_channels=8*4,out_channels=c3,kernel_size=5,stride=1, padding=2)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=32, nhead=8, dim_feedforward=64, dropout=0.001)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=3)\n",
    "        \n",
    "        self.output = nn.Conv1d(in_channels=c3,out_channels=11,kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.beta_dist = torch.distributions.beta.Beta(2,2)\n",
    "        \n",
    "        self.ma_aoa_lin1 = nn.Linear(2,16)\n",
    "        self.ma_aoa_relu1 = nn.ReLU()\n",
    "        self.ma_aoa_lin2 = nn.Linear(16,32)\n",
    "        self.ma_aoa_relu2 = nn.ReLU()\n",
    "        \n",
    "        latenc_layers = nn.TransformerDecoderLayer(d_model=32, nhead=8, dim_feedforward=64, dropout=0.001)\n",
    "        self.latenc_transformer = nn.TransformerDecoder(latenc_layers, num_layers=2)        \n",
    "        \n",
    "        decoder_layers = nn.TransformerDecoderLayer(d_model=32, nhead=8, dim_feedforward=64, dropout=0.001)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers=3)\n",
    "        \n",
    "    def data_augmentation(self, x):\n",
    "        \n",
    "        s = x[:,1]\n",
    "        ds = s[:,1:] - s[:,:-1]\n",
    "        \n",
    "        rv = self.beta_dist.rsample([s.shape[0], s.shape[1]-2]).to(self.device)\n",
    "        snew = s.clone()\n",
    "        #print(snew.device, rv.device, ds.device)\n",
    "        snew[:,1:-1] += 0.5 * ( (rv > 0)*ds[:,1:] - (rv < 0)* ds[:,:-1] )\n",
    "\n",
    "        #xnew = interp(s, x, snew)\n",
    "        \n",
    "        xnew = torch.zeros_like(x, device=self.device)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                xnew[i,j] = interp(s[i], x[i,j], snew[i])\n",
    "        \n",
    "        indices = torch.rand(xnew.shape[1]) >= 0.25\n",
    "        xnew = xnew[:,indices]\n",
    "        \n",
    "        return xnew\n",
    "    \n",
    "    def augment_output(self, x, y):\n",
    "        \n",
    "        s = x[:,1]\n",
    "        ds = s[:,1:] - s[:,:-1]\n",
    "        \n",
    "        rv = self.beta_dist.rsample([s.shape[0], s.shape[1]-2]).to(self.device)\n",
    "        snew = s.clone()\n",
    "        #print(snew.device, rv.device, ds.device)\n",
    "        snew[:,1:-1] += 0.5 * ( (rv > 0)*ds[:,1:] - (rv < 0)* ds[:,:-1] )\n",
    "\n",
    "        #xnew = interp(s, x, snew)\n",
    "        \n",
    "        xnew = torch.zeros_like(x, device=self.device)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                xnew[i,j] = interp(s[i], x[i,j], snew[i])\n",
    "                \n",
    "        ynew = torch.zeros_like(y, device=self.device)\n",
    "        for i in range(y.shape[0]):\n",
    "            for j in range(y.shape[1]):\n",
    "                ynew[i,j] = interp(s[i], y[i,j], snew[i])\n",
    "        \n",
    "        indices = torch.rand(xnew.shape[1]) >= 0.25\n",
    "        xnew = xnew[:,indices]\n",
    "        ynew = ynew[:,indices]\n",
    "        \n",
    "        return xnew, ynew\n",
    "        \n",
    "    def airfoil_encoder(self, x):\n",
    "        \n",
    "        #xxx = torch.cat((x, x, x), dim=2)\n",
    "        #x_0 = self.layer_0(xxx)\n",
    "        x_0 = self.layer_0(x)\n",
    "\n",
    "        x_11 = self.relu_11(self.layer_11(x_0))\n",
    "        x_12 = self.relu_12(self.layer_12(x_11))\n",
    "        x_13 = self.relu_13(self.layer_13(x_12))\n",
    "        x_14 = self.relu_14(self.layer_14(x_13))\n",
    "\n",
    "        x_1 = torch.cat((x_11, x_12, x_13, x_14), dim=1)\n",
    "        \n",
    "        x_2 = self.relu_2(self.layer_2(x_1))\n",
    "        \n",
    "        ### Insert Transformer!\n",
    "        \n",
    "        x_3 = x_2\n",
    "        \n",
    "        return x_3\n",
    "        \n",
    "    def latent_encoder(self, x_3, ma, aoa):\n",
    "        \n",
    "        #ma = torch.ones(x_3.shape[0], 1,193).to(self.device)*ma.view(-1, 1, 1)\n",
    "        #aoa = torch.ones(x_3.shape[0], 1, 193).to(self.device)*aoa.view(-1, 1, 1)\n",
    "        \n",
    "        #print(\"lat\", x_3.device, ma.device, aoa.device)\n",
    "        \n",
    "        ma_aoa = torch.stack((ma,aoa)).to(self.device)\n",
    "        ma_aoa1 = self.ma_aoa_relu1(self.ma_aoa_lin1(ma_aoa.T))\n",
    "        ma_aoa2 = self.ma_aoa_relu2(self.ma_aoa_lin2(ma_aoa1)).view(-1,1,32)\n",
    "        \n",
    "        #relu(lin(cat((ma,aoa))))\n",
    "        #x_4 = torch.cat((x_3, aoa, ma), dim=1)        \n",
    "        \n",
    "        ### Insert Transformer!\n",
    "        \n",
    "        #z = self.transformer_encoder(x_4.transpose(1,2))\n",
    "        \n",
    "        #print(ma_aoa2.shape, x_3.shape)\n",
    "        #print(ma_aoa2.device, x_3.device)\n",
    "        \n",
    "        z = self.latenc_transformer(ma_aoa2, x_3.transpose(1,2))\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    \n",
    "    def airfoil_predictor(self, z, x_output):\n",
    "        \n",
    "        ### Insert Transformer!\n",
    "        \n",
    "        #y = self.output(z.transpose(1,2))      \n",
    "        \n",
    "        \n",
    "        #x3_output = self.airfoil_encoder(x_output)\n",
    "        \n",
    "        #print(z.shape, x_output.shape, x3_output.shape)\n",
    "        \n",
    "        #y = self.transformer_decoder(x3_output, z.transpose(1,2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        x3_output = self.airfoil_encoder(x_output).transpose(1,2).transpose(0,1)\n",
    "        z = z.transpose(0,1)\n",
    "        \n",
    "        #print(z.shape, x_output.shape, x3_output.shape)\n",
    "\n",
    "        y = self.transformer_decoder(x3_output, z).transpose(0,1).transpose(1,2)\n",
    "        \n",
    "        out = self.output(y)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(self, x, ma, aoa):\n",
    "        \n",
    "        xnew = self.data_augmentation(x)\n",
    "        x3 = self.airfoil_encoder(xnew)\n",
    "        z = self.latent_encoder(x3, ma, aoa)\n",
    "        y = self.airfoil_predictor(z)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        qoip, ma, _, aoa = batch\n",
    "        \n",
    "        #print(qoip.device, ma.device, aoa.device)\n",
    "        \n",
    "        x = qoip[:,:6,:]\n",
    "        y_target = qoip\n",
    "        \n",
    "        xout, y_target = self.augment_output(x.clone(), y_target.clone())\n",
    "        \n",
    "        xnew = self.data_augmentation(x.clone())\n",
    "        x3 = self.airfoil_encoder(xnew)\n",
    "        z = self.latent_encoder(x3, ma, aoa)\n",
    "        #y = self.airfoil_predictor(z, self.data_augmentation(x))\n",
    "        y = self.airfoil_predictor(z, xout)\n",
    "        \n",
    "        #y[:,5,:] = 10. * y[:,5,:]\n",
    "        #y_target[:,5,:] = 10. * y_target[:,5,:]\n",
    "        \n",
    "        \n",
    "        loss1 = F.mse_loss(y, y_target) * 1e6\n",
    "        \n",
    "        loss = loss1\n",
    "        \n",
    "        self.log('train_loss', loss1)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        qoip, ma, _, aoa = batch\n",
    "        x = qoip[:,:6,:]\n",
    "        y_target = qoip\n",
    "        \n",
    "        #print(qoip.device, ma.device, aoa.device)\n",
    "        \n",
    "        #xnew = self.data_augmentation(x)\n",
    "        x3 = self.airfoil_encoder(x)\n",
    "        z = self.latent_encoder(x3, ma, aoa)\n",
    "        y = self.airfoil_predictor(z, x)\n",
    "        \n",
    "        #y[:,5,:] *= 10.\n",
    "        #y_target[:,5,:] *= 10.\n",
    "        \n",
    "        loss1 = F.mse_loss(y, y_target) * 1e6\n",
    "        \n",
    "        loss = loss1\n",
    "        \n",
    "        self.log('val_loss', loss1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2000, eta_min=0.0001)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        #print(\"get dataloader \", self.batch_size)\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, num_workers=0, shuffle=True, pin_memory=True)    \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=len(test_dataset), num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AirfoilModel()\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qoip, ma, _, aoa = dataset[:3]\n",
    "x = qoip[:,:6]\n",
    "\n",
    "ma_aoa = torch.stack((ma, aoa))\n",
    "w = torch.randn(8,2)\n",
    "\n",
    "ma_aoa_lin = nn.Linear(2,8)\n",
    "ma_aoa_relu = nn.ReLU()\n",
    "\n",
    "ma_aoa = ma_aoa_lin(ma_aoa.T)\n",
    "\n",
    "ma_aoa.shape\n",
    "\n",
    "x3 = model.airfoil_encoder(x)\n",
    "\n",
    "x3.shape, ma_aoa.shape\n",
    "\n",
    "#torch.cat((x3, ma_aoa.view(-1,8,1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset[:3]\n",
    "\n",
    "qoip, ma, _, aoa = batch\n",
    "\n",
    "#print(qoip.device, ma.device, aoa.device)\n",
    "\n",
    "x = qoip[:,:6,:]\n",
    "y_target = qoip\n",
    "\n",
    "xnew = model.data_augmentation(x)\n",
    "x3 = model.airfoil_encoder(xnew)\n",
    "z = model.latent_encoder(x3, ma, aoa)\n",
    "print(z.shape)\n",
    "\n",
    "#y = model.airfoil_predictor(z, x)\n",
    "\n",
    "x_output = x\n",
    "\n",
    "x3_output = model.airfoil_encoder(x_output).transpose(1,2).transpose(0,1)\n",
    "z = z.transpose(0,1)\n",
    "        \n",
    "print(z.shape, x_output.shape, x3_output.shape)\n",
    "\n",
    "y = model.transformer_decoder(x3_output, z).transpose(0,1) #.transpose(1,2)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset[:3]\n",
    "\n",
    "model.training_step(batch,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AirfoilModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.distributions.beta.Beta(2,2)\n",
    "beta.rsample([2,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AirfoilModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "trainer = Trainer(gpus=1, weights_summary='full', precision=16, check_val_every_n_epoch=2, max_epochs=10_000,\n",
    "                 limit_train_batches=0.5, auto_lr_find=False, callbacks=[lr_monitor]) #, auto_scale_batch_size=None\n",
    "#train_loader = DataLoader(train_dataset, batch_size=1468, shuffle=True, pin_memory=True)\n",
    "#val_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "#trainer.fit(model, train_loader)\n",
    "#trainer.tune(model)\n",
    "model.batch_size = 8\n",
    "model.train_variance = 0.01 #1.0\n",
    "model.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "    | Name                                                 | Type                    | Params\n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   | layer_0                                              | Conv1d                  | 496   \n",
      "1   | layer_11                                             | Conv1d                  | 392   \n",
      "2   | layer_12                                             | Conv1d                  | 200   \n",
      "3   | layer_13                                             | Conv1d                  | 200   \n",
      "4   | layer_14                                             | Conv1d                  | 200   \n",
      "5   | relu_11                                              | ReLU                    | 0     \n",
      "6   | relu_12                                              | ReLU                    | 0     \n",
      "7   | relu_13                                              | ReLU                    | 0     \n",
      "8   | relu_14                                              | ReLU                    | 0     \n",
      "9   | layer_2                                              | Conv1d                  | 5.2 K \n",
      "10  | relu_2                                               | ReLU                    | 0     \n",
      "11  | transformer_encoder                                  | TransformerEncoder      | 25.6 K\n",
      "12  | transformer_encoder.layers                           | ModuleList              | 25.6 K\n",
      "13  | transformer_encoder.layers.0                         | TransformerEncoderLayer | 8.5 K \n",
      "14  | transformer_encoder.layers.0.self_attn               | MultiheadAttention      | 4.2 K \n",
      "15  | transformer_encoder.layers.0.self_attn.out_proj      | _LinearWithBias         | 1.1 K \n",
      "16  | transformer_encoder.layers.0.linear1                 | Linear                  | 2.1 K \n",
      "17  | transformer_encoder.layers.0.dropout                 | Dropout                 | 0     \n",
      "18  | transformer_encoder.layers.0.linear2                 | Linear                  | 2.1 K \n",
      "19  | transformer_encoder.layers.0.norm1                   | LayerNorm               | 64    \n",
      "20  | transformer_encoder.layers.0.norm2                   | LayerNorm               | 64    \n",
      "21  | transformer_encoder.layers.0.dropout1                | Dropout                 | 0     \n",
      "22  | transformer_encoder.layers.0.dropout2                | Dropout                 | 0     \n",
      "23  | transformer_encoder.layers.1                         | TransformerEncoderLayer | 8.5 K \n",
      "24  | transformer_encoder.layers.1.self_attn               | MultiheadAttention      | 4.2 K \n",
      "25  | transformer_encoder.layers.1.self_attn.out_proj      | _LinearWithBias         | 1.1 K \n",
      "26  | transformer_encoder.layers.1.linear1                 | Linear                  | 2.1 K \n",
      "27  | transformer_encoder.layers.1.dropout                 | Dropout                 | 0     \n",
      "28  | transformer_encoder.layers.1.linear2                 | Linear                  | 2.1 K \n",
      "29  | transformer_encoder.layers.1.norm1                   | LayerNorm               | 64    \n",
      "30  | transformer_encoder.layers.1.norm2                   | LayerNorm               | 64    \n",
      "31  | transformer_encoder.layers.1.dropout1                | Dropout                 | 0     \n",
      "32  | transformer_encoder.layers.1.dropout2                | Dropout                 | 0     \n",
      "33  | transformer_encoder.layers.2                         | TransformerEncoderLayer | 8.5 K \n",
      "34  | transformer_encoder.layers.2.self_attn               | MultiheadAttention      | 4.2 K \n",
      "35  | transformer_encoder.layers.2.self_attn.out_proj      | _LinearWithBias         | 1.1 K \n",
      "36  | transformer_encoder.layers.2.linear1                 | Linear                  | 2.1 K \n",
      "37  | transformer_encoder.layers.2.dropout                 | Dropout                 | 0     \n",
      "38  | transformer_encoder.layers.2.linear2                 | Linear                  | 2.1 K \n",
      "39  | transformer_encoder.layers.2.norm1                   | LayerNorm               | 64    \n",
      "40  | transformer_encoder.layers.2.norm2                   | LayerNorm               | 64    \n",
      "41  | transformer_encoder.layers.2.dropout1                | Dropout                 | 0     \n",
      "42  | transformer_encoder.layers.2.dropout2                | Dropout                 | 0     \n",
      "43  | output                                               | Conv1d                  | 363   \n",
      "44  | ma_aoa_lin1                                          | Linear                  | 48    \n",
      "45  | ma_aoa_relu1                                         | ReLU                    | 0     \n",
      "46  | ma_aoa_lin2                                          | Linear                  | 544   \n",
      "47  | ma_aoa_relu2                                         | ReLU                    | 0     \n",
      "48  | latenc_transformer                                   | TransformerDecoder      | 25.7 K\n",
      "49  | latenc_transformer.layers                            | ModuleList              | 25.7 K\n",
      "50  | latenc_transformer.layers.0                          | TransformerDecoderLayer | 12.8 K\n",
      "51  | latenc_transformer.layers.0.self_attn                | MultiheadAttention      | 4.2 K \n",
      "52  | latenc_transformer.layers.0.self_attn.out_proj       | _LinearWithBias         | 1.1 K \n",
      "53  | latenc_transformer.layers.0.multihead_attn           | MultiheadAttention      | 4.2 K \n",
      "54  | latenc_transformer.layers.0.multihead_attn.out_proj  | _LinearWithBias         | 1.1 K \n",
      "55  | latenc_transformer.layers.0.linear1                  | Linear                  | 2.1 K \n",
      "56  | latenc_transformer.layers.0.dropout                  | Dropout                 | 0     \n",
      "57  | latenc_transformer.layers.0.linear2                  | Linear                  | 2.1 K \n",
      "58  | latenc_transformer.layers.0.norm1                    | LayerNorm               | 64    \n",
      "59  | latenc_transformer.layers.0.norm2                    | LayerNorm               | 64    \n",
      "60  | latenc_transformer.layers.0.norm3                    | LayerNorm               | 64    \n",
      "61  | latenc_transformer.layers.0.dropout1                 | Dropout                 | 0     \n",
      "62  | latenc_transformer.layers.0.dropout2                 | Dropout                 | 0     \n",
      "63  | latenc_transformer.layers.0.dropout3                 | Dropout                 | 0     \n",
      "64  | latenc_transformer.layers.1                          | TransformerDecoderLayer | 12.8 K\n",
      "65  | latenc_transformer.layers.1.self_attn                | MultiheadAttention      | 4.2 K \n",
      "66  | latenc_transformer.layers.1.self_attn.out_proj       | _LinearWithBias         | 1.1 K \n",
      "67  | latenc_transformer.layers.1.multihead_attn           | MultiheadAttention      | 4.2 K \n",
      "68  | latenc_transformer.layers.1.multihead_attn.out_proj  | _LinearWithBias         | 1.1 K \n",
      "69  | latenc_transformer.layers.1.linear1                  | Linear                  | 2.1 K \n",
      "70  | latenc_transformer.layers.1.dropout                  | Dropout                 | 0     \n",
      "71  | latenc_transformer.layers.1.linear2                  | Linear                  | 2.1 K \n",
      "72  | latenc_transformer.layers.1.norm1                    | LayerNorm               | 64    \n",
      "73  | latenc_transformer.layers.1.norm2                    | LayerNorm               | 64    \n",
      "74  | latenc_transformer.layers.1.norm3                    | LayerNorm               | 64    \n",
      "75  | latenc_transformer.layers.1.dropout1                 | Dropout                 | 0     \n",
      "76  | latenc_transformer.layers.1.dropout2                 | Dropout                 | 0     \n",
      "77  | latenc_transformer.layers.1.dropout3                 | Dropout                 | 0     \n",
      "78  | transformer_decoder                                  | TransformerDecoder      | 38.5 K\n",
      "79  | transformer_decoder.layers                           | ModuleList              | 38.5 K\n",
      "80  | transformer_decoder.layers.0                         | TransformerDecoderLayer | 12.8 K\n",
      "81  | transformer_decoder.layers.0.self_attn               | MultiheadAttention      | 4.2 K \n",
      "82  | transformer_decoder.layers.0.self_attn.out_proj      | _LinearWithBias         | 1.1 K \n",
      "83  | transformer_decoder.layers.0.multihead_attn          | MultiheadAttention      | 4.2 K \n",
      "84  | transformer_decoder.layers.0.multihead_attn.out_proj | _LinearWithBias         | 1.1 K \n",
      "85  | transformer_decoder.layers.0.linear1                 | Linear                  | 2.1 K \n",
      "86  | transformer_decoder.layers.0.dropout                 | Dropout                 | 0     \n",
      "87  | transformer_decoder.layers.0.linear2                 | Linear                  | 2.1 K \n",
      "88  | transformer_decoder.layers.0.norm1                   | LayerNorm               | 64    \n",
      "89  | transformer_decoder.layers.0.norm2                   | LayerNorm               | 64    \n",
      "90  | transformer_decoder.layers.0.norm3                   | LayerNorm               | 64    \n",
      "91  | transformer_decoder.layers.0.dropout1                | Dropout                 | 0     \n",
      "92  | transformer_decoder.layers.0.dropout2                | Dropout                 | 0     \n",
      "93  | transformer_decoder.layers.0.dropout3                | Dropout                 | 0     \n",
      "94  | transformer_decoder.layers.1                         | TransformerDecoderLayer | 12.8 K\n",
      "95  | transformer_decoder.layers.1.self_attn               | MultiheadAttention      | 4.2 K \n",
      "96  | transformer_decoder.layers.1.self_attn.out_proj      | _LinearWithBias         | 1.1 K \n",
      "97  | transformer_decoder.layers.1.multihead_attn          | MultiheadAttention      | 4.2 K \n",
      "98  | transformer_decoder.layers.1.multihead_attn.out_proj | _LinearWithBias         | 1.1 K \n",
      "99  | transformer_decoder.layers.1.linear1                 | Linear                  | 2.1 K \n",
      "100 | transformer_decoder.layers.1.dropout                 | Dropout                 | 0     \n",
      "101 | transformer_decoder.layers.1.linear2                 | Linear                  | 2.1 K \n",
      "102 | transformer_decoder.layers.1.norm1                   | LayerNorm               | 64    \n",
      "103 | transformer_decoder.layers.1.norm2                   | LayerNorm               | 64    \n",
      "104 | transformer_decoder.layers.1.norm3                   | LayerNorm               | 64    \n",
      "105 | transformer_decoder.layers.1.dropout1                | Dropout                 | 0     \n",
      "106 | transformer_decoder.layers.1.dropout2                | Dropout                 | 0     \n",
      "107 | transformer_decoder.layers.1.dropout3                | Dropout                 | 0     \n",
      "108 | transformer_decoder.layers.2                         | TransformerDecoderLayer | 12.8 K\n",
      "109 | transformer_decoder.layers.2.self_attn               | MultiheadAttention      | 4.2 K \n",
      "110 | transformer_decoder.layers.2.self_attn.out_proj      | _LinearWithBias         | 1.1 K \n",
      "111 | transformer_decoder.layers.2.multihead_attn          | MultiheadAttention      | 4.2 K \n",
      "112 | transformer_decoder.layers.2.multihead_attn.out_proj | _LinearWithBias         | 1.1 K \n",
      "113 | transformer_decoder.layers.2.linear1                 | Linear                  | 2.1 K \n",
      "114 | transformer_decoder.layers.2.dropout                 | Dropout                 | 0     \n",
      "115 | transformer_decoder.layers.2.linear2                 | Linear                  | 2.1 K \n",
      "116 | transformer_decoder.layers.2.norm1                   | LayerNorm               | 64    \n",
      "117 | transformer_decoder.layers.2.norm2                   | LayerNorm               | 64    \n",
      "118 | transformer_decoder.layers.2.norm3                   | LayerNorm               | 64    \n",
      "119 | transformer_decoder.layers.2.dropout1                | Dropout                 | 0     \n",
      "120 | transformer_decoder.layers.2.dropout2                | Dropout                 | 0     \n",
      "121 | transformer_decoder.layers.2.dropout3                | Dropout                 | 0     \n",
      "---------------------------------------------------------------------------------------------------\n",
      "97.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "97.4 K    Total params\n",
      "0.390     Total estimated model params size (MB)\n",
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 670.00 MiB (GPU 0; 2.00 GiB total capacity; 696.28 MiB already allocated; 430.30 MiB free; 716.00 MiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-45d4afebefac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Trainer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# double dispatch to initiate the training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Trainer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;31m# set stage for logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[1;34m(self, ref_model)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[1;31m# run eval step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;31m# allow no returns from eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[1;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[0;32m    730\u001b[0m                 \u001b[1;31m# lightning module methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"evaluation_step_and_end\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\trainer\\evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"validation_step\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"validation_step\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;31m# capture any logged information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-13597eade671>\u001b[0m in \u001b[0;36mvalidation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m#xnew = self.data_augmentation(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mairfoil_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maoa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mairfoil_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-13597eade671>\u001b[0m in \u001b[0;36mlatent_encoder\u001b[1;34m(self, x_3, ma, aoa)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m#print(ma_aoa2.device, x_3.device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatenc_transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mma_aoa2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001b[0m\u001b[0;32m    232\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n\u001b[0m\u001b[0;32m    368\u001b[0m                                    key_padding_mask=memory_key_padding_mask)[0]\n\u001b[0;32m    369\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m    978\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[0;32m    979\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m    981\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   4802\u001b[0m         \u001b[0mattn_output_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_output_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4804\u001b[1;33m     \u001b[0mattn_output_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4805\u001b[0m     \u001b[0mattn_output_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MA2\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1581\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1583\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1584\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1585\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 670.00 MiB (GPU 0; 2.00 GiB total capacity; 696.28 MiB already allocated; 430.30 MiB free; 716.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 21\n",
    "qoip, ma, _, aoa = dataset[i]\n",
    "qoip = qoip.view(-1,11,193)\n",
    "\n",
    "x = qoip[:,:6,:]\n",
    "y = model(x, ma, aoa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model.cpu()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    i = 23\n",
    "    qoip, ma, _, aoa = test_dataset[i]\n",
    "    qoip = qoip.view(-1,11,193)\n",
    "    print(ma, aoa)\n",
    "\n",
    "    x = qoip[:,:6,:]\n",
    "    #y = model(x, ma, aoa)\n",
    "\n",
    "\n",
    "    x3 = model.airfoil_encoder(x)\n",
    "    z = model.latent_encoder(x3, ma, aoa)\n",
    "    y = model.airfoil_predictor(z, x)\n",
    "\n",
    "\n",
    "\n",
    "    k = qoip.shape[1]\n",
    "    y = y.detach()\n",
    "\n",
    "    fig, ax = plt.subplots(k, figsize=(12,32))\n",
    "    fields = [\"s\", \"sn\", \"nx\", \"ny\", \"x\", \"y\", \"Density\", \"Energy\", \"Pressure_Coefficient\", \"Skin_Friction_Coefficient_x\", \"Skin_Friction_Coefficient_y\"]\n",
    "\n",
    "    for i in range(k):\n",
    "        ax[i].plot(qoip[0,1], qoip[0,i], \"o\")\n",
    "        ax[i].plot(qoip[0,1], y[0,i], \"x\")\n",
    "        ax[i].set_title(fields[i])\n",
    "        #print(i, fields[i], F.mse_loss(qoip[0,i], y[0,i])*1e6)\n",
    "        print(i, fields[i], torch.pow(y[0,i] - qoip[0,i], 2).sum() / y.shape[2]*1e6)\n",
    "\n",
    "    #y[0,5] = y[0,5]*10.\n",
    "    #qoip[0,5] = qoip[0,5]*10.\n",
    "\n",
    "    #print(F.mse_loss(y, qoip[:,:])*1e6)\n",
    "    print(torch.pow(y[0,:] - qoip[0,:], 2).sum() / y.shape[1] / y.shape[2]*1e6)\n",
    "\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qoip[0,4,:], qoip[0,5,:])\n",
    "plt.plot(y[0,4,:], y[0,5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.pow(y - qoip[:,:], 2).sum(), y.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y[0,2]*y[0,8]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(qoip[0,2]*qoip[0,8]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qoip[0,0],y[0,2]*y[0,8])\n",
    "plt.plot(qoip[0,0],qoip[0,2]*qoip[0,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qoip[0,0],y[0,3]*y[0,8])\n",
    "plt.plot(qoip[0,0],qoip[0,3]*qoip[0,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma, aoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MA, AOA, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(dataset, open(\"save/T007_Transformer/full_dataset.p\", \"wb\"))\n",
    "pickle.dump(train_dataset, open(\"save/T007_Transformer/train_dataset.p\", \"wb\"))\n",
    "pickle.dump(test_dataset, open(\"save/T007_Transformer/test_dataset.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dataset, open(\"save/T007_Transformer/full_dataset.p\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pickle.load(open(\"save/T007_Transformer/train_dataset.p\", \"rb\"))\n",
    "test_dataset = pickle.load(open(\"save/T007_Transformer/test_dataset.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1905, 337)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}